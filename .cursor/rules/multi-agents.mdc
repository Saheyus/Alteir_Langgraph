---
description: Architecture multi-agents avec LangGraph et MCP Notion
globs: agents/**/*.py,workflows/**/*.py,config/**/*.py
alwaysApply: false
---

# SystÃ¨me Multi-Agents GDD Alteir

## ğŸ¤– ModÃ¨les LLM

### OpenAI GPT-5-nano (Production)
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-5-nano",  # VALIDE depuis aoÃ»t 2025
    use_responses_api=True,
    extra_body={
        "reasoning": {"effort": "minimal"},
        "max_output_tokens": 1000,
    }
)
```

### Multi-Provider avec LLMAdapter
**TOUJOURS utiliser `LLMAdapter`** pour abstraction fournisseur :

```python
from agents.base.llm_utils import LLMAdapter

adapter = LLMAdapter(llm)  # Fonctionne avec OpenAI, Anthropic, Mistral, Ollama
result = adapter.get_structured_output(prompt, schema=MySchema)
```

## ğŸ—ï¸ Architecture Agents

### CrÃ©er un nouvel agent
```python
from agents.base.base_agent import BaseAgent, AgentResult
from agents.base.domain_config import DomainConfig

class MyAgent(BaseAgent):
    def __init__(self, domain_config: DomainConfig, llm=None):
        super().__init__(domain_config, llm)
    
    def process(self, input_data, context=None) -> AgentResult:
        # 1. Utiliser self.domain_config pour spÃ©cificitÃ©s
        # 2. Utiliser self.llm pour appels LLM
        # 3. Retourner AgentResult
        pass
```

### 4 Agents GÃ©nÃ©riques
1. **WriterAgent**: GÃ©nÃ©ration contenu
2. **ReviewerAgent**: Analyse cohÃ©rence
3. **CorrectorAgent**: Correction linguistique
4. **ValidatorAgent**: Validation finale

**Ne PAS crÃ©er de nouveaux agents** â†’ CrÃ©er une **DomainConfig** Ã  la place !

## ğŸ“Š Structured Outputs (OBLIGATOIRE)

### âœ… TOUJOURS utiliser Structured Outputs
```python
from pydantic import BaseModel, Field

class MyResult(BaseModel):
    field1: str = Field(description="...")
    field2: List[str]

adapter = LLMAdapter(llm)
result = adapter.get_structured_output(prompt, schema=MyResult)
# result est typÃ©, pas de parsing manuel !
```

### âŒ NE JAMAIS faire de parsing manuel
```python
# âŒ Ã‰VITER CECI
if '[CORRECTION:' in line:
    parts = line.split(']', 1)

# âœ… FAIRE CECI
result = adapter.get_structured_output(prompt, schema=CorrectionResult)
for corr in result.corrections:
    print(corr.type, corr.original)
```

## ğŸ”„ Workflows LangGraph

### Pattern Standard
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class MyState(TypedDict):
    content: str
    metadata: dict

def node_function(state: MyState) -> dict:
    return {"content": "..."}

graph = StateGraph(MyState)
graph.add_node("node1", node_function)
graph.add_edge("node1", END)
app = graph.compile()
```

### Sauvegarde RÃ©sultats
- **JSON** (`outputs/*.json`): Ã‰tat complet
- **Markdown** (`outputs/*.md`): Contenu lisible

## ğŸ“ Conventions Code

### Nommage
- **Classes**: `PascalCase` (WriterAgent, DomainConfig)
- **Fonctions/Variables**: `snake_case` (process_content)
- **Constantes**: `UPPER_SNAKE_CASE` (PERSONNAGES_CONFIG)

### Type Hints OBLIGATOIRES
```python
def process(self, content: str, context: Dict[str, Any] = None) -> AgentResult:
    pass
```

### Docstrings Google
```python
def my_function(param1: str) -> bool:
    """
    Description courte.
    
    Args:
        param1: Description
        
    Returns:
        Description retour
    """
    pass
```

## ğŸš¨ Erreurs Ã  Ã‰viter

âŒ Parsing manuel de texte LLM
âŒ Hardcoder le provider (toujours `LLMAdapter`)
âŒ Oublier type hints
âŒ Ignorer structured outputs
âŒ CrÃ©er agents spÃ©cialisÃ©s â†’ CrÃ©er `DomainConfig`
âŒ ModÃ¨les inexistants (GPT-5-nano existe depuis aoÃ»t 2025)

## âœ… Bonnes Pratiques

âœ“ `LLMAdapter` pour multi-provider
âœ“ Structured Outputs avec Pydantic
âœ“ `DomainConfig` pour spÃ©cialisation
âœ“ Sauvegarder JSON + Markdown
âœ“ Tester avec plusieurs providers
âœ“ Type hints partout
âœ“ Workflows LangGraph simples
