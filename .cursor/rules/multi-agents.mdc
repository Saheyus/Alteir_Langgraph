---
description: Architecture multi-agents avec LangGraph et MCP Notion
globs: agents/**/*.py,workflows/**/*.py,config/**/*.py
alwaysApply: false
---

# SystÃ¨me Multi-Agents GDD Alteir

## ğŸ¤– ModÃ¨les LLM

### OpenAI GPT-5-nano (Production)
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-5-nano",  # VALIDE depuis aoÃ»t 2025
    use_responses_api=True,
    extra_body={
        "reasoning": {"effort": "minimal"},
        "max_output_tokens": 1000,
    }
)
```

### Multi-Provider avec LLMAdapter
**TOUJOURS utiliser `LLMAdapter`** pour abstraction fournisseur :

```python
from agents.base.llm_utils import LLMAdapter

adapter = LLMAdapter(llm)  # Fonctionne avec OpenAI, Anthropic, Mistral, Ollama
result = adapter.get_structured_output(prompt, schema=MySchema)
```

## ğŸ—ï¸ Architecture Agents

### CrÃ©er un nouvel agent
```python
from agents.base.base_agent import BaseAgent, AgentResult
from agents.base.domain_config import DomainConfig

class MyAgent(BaseAgent):
    def __init__(self, domain_config: DomainConfig, llm=None):
        super().__init__(domain_config, llm)
    
    def process(self, input_data, context=None) -> AgentResult:
        # 1. Utiliser self.domain_config pour spÃ©cificitÃ©s
        # 2. Utiliser self.llm pour appels LLM
        # 3. Retourner AgentResult
        pass
```

### 4 Agents GÃ©nÃ©riques
1. **WriterAgent**: GÃ©nÃ©ration contenu
2. **ReviewerAgent**: Analyse cohÃ©rence
3. **CorrectorAgent**: Correction linguistique
4. **ValidatorAgent**: Validation finale

**Ne PAS crÃ©er de nouveaux agents** â†’ CrÃ©er une **DomainConfig** Ã  la place !

## ğŸ“Š Structured Outputs (OBLIGATOIRE)

### âœ… TOUJOURS utiliser Structured Outputs
```python
from pydantic import BaseModel, Field

class MyResult(BaseModel):
    field1: str = Field(description="...")
    field2: List[str]

adapter = LLMAdapter(llm)
result = adapter.get_structured_output(prompt, schema=MyResult)
# result est typÃ©, pas de parsing manuel !
```

### âŒ NE JAMAIS faire de parsing manuel
```python
# âŒ Ã‰VITER CECI
if '[CORRECTION:' in line:
    parts = line.split(']', 1)

# âœ… FAIRE CECI
result = adapter.get_structured_output(prompt, schema=CorrectionResult)
for corr in result.corrections:
    print(corr.type, corr.original)
```

## ğŸ”„ Workflows LangGraph

### Pattern Standard
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class MyState(TypedDict):
    content: str
    metadata: dict

def node_function(state: MyState) -> dict:
    return {"content": "..."}

graph = StateGraph(MyState)
graph.add_node("node1", node_function)
graph.add_edge("node1", END)
app = graph.compile()
```

### Sauvegarde RÃ©sultats
- **JSON** (`outputs/*.json`): Ã‰tat complet
- **Markdown** (`outputs/*.md`): Contenu lisible

## ğŸ–¥ï¸ Lancement Interfaces

### Fichiers .cmd (Windows - RecommandÃ©)
```cmd
# Menu principal avec toutes les options
GDD_Alteir.cmd

# Lancer directement l'application
lancer_app.cmd

# Lancer les tests
lancer_tests.cmd

# Lancer une dÃ©mo
lancer_demo.cmd
```

### Streamlit (Manuel)
```bash
# IMPORTANT: Utiliser chemin ABSOLU sur Windows
python -m streamlit run "F:\Projets\Langgraph Alteir\app_streamlit.py"

# âŒ NE PAS faire (ne trouve pas le fichier en background)
streamlit run app_streamlit.py
```

L'app s'ouvre automatiquement sur **http://localhost:8501**

### CLI
```bash
python app_cli.py
```

### Demo Rich
```bash
python demo_workflow.py
```

## ğŸ“ Conventions Code

### Nommage
- **Classes**: `PascalCase` (WriterAgent, DomainConfig)
- **Fonctions/Variables**: `snake_case` (process_content)
- **Constantes**: `UPPER_SNAKE_CASE` (PERSONNAGES_CONFIG)

### Type Hints OBLIGATOIRES
```python
def process(self, content: str, context: Dict[str, Any] = None) -> AgentResult:
    pass
```

### Docstrings Google
```python
def my_function(param1: str) -> bool:
    """
    Description courte.
    
    Args:
        param1: Description
        
    Returns:
        Description retour
    """
    pass
```

## ğŸš¨ Erreurs Ã  Ã‰viter

âŒ Parsing manuel de texte LLM
âŒ Hardcoder le provider (toujours `LLMAdapter`)
âŒ Oublier type hints
âŒ Ignorer structured outputs
âŒ CrÃ©er agents spÃ©cialisÃ©s â†’ CrÃ©er `DomainConfig`
âŒ ModÃ¨les inexistants (GPT-5-nano existe depuis aoÃ»t 2025)

## ğŸ§ª Tests

### Structure des Tests
```
tests/
  test_notion_integration.py    # Tests MCP Notion
  test_narrative_template.py    # Tests templates narratifs
  test_real_data.py            # Tests avec vraies donnÃ©es
```

### CrÃ©er un Test
```python
#!/usr/bin/env python3
"""
Tests pour [domaine/fonctionnalitÃ©]
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from rich.console import Console
from rich.panel import Panel

console = Console()

def test_my_feature():
    """Test: Description du test"""
    console.print(Panel("[bold cyan]=== Test: Mon Test ===[/bold cyan]", expand=False))
    
    try:
        # Code de test
        result = my_function()
        
        if result:
            console.print("[green]âœ“ Test rÃ©ussi[/green]")
            return True
        else:
            console.print("[red]âœ— Test Ã©chouÃ©[/red]")
            return False
            
    except Exception as e:
        console.print(f"[bold red]âœ— Erreur:[/bold red] {e}")
        return False

def run_tests():
    """ExÃ©cute tous les tests"""
    results = [
        ("Mon Test", test_my_feature()),
    ]
    
    # RÃ©sumÃ©
    for test_name, success in results:
        status = "[green]âœ“[/green]" if success else "[red]âœ—[/red]"
        console.print(f"{status} {test_name}")

if __name__ == "__main__":
    run_tests()
```

### Lancer les Tests
```bash
# Test spÃ©cifique
python tests/test_narrative_template.py

# Tous les tests d'intÃ©gration
python tests/test_notion_integration.py

# Tests avec vraies donnÃ©es
python tests/test_real_data.py
```

## âœ… Bonnes Pratiques

âœ“ `LLMAdapter` pour multi-provider
âœ“ Structured Outputs avec Pydantic
âœ“ `DomainConfig` pour spÃ©cialisation
âœ“ Sauvegarder JSON + Markdown
âœ“ Tester avec plusieurs providers
âœ“ Type hints partout
âœ“ Workflows LangGraph simples
âœ“ Tests permanents dans `tests/` (pas de fichiers temporaires)
âœ“ Utiliser Rich pour l'affichage des tests
