# Cursor Rules - Syst√®me Multi-Agents GDD Alteir

## üéØ Contexte du Projet
Syst√®me multi-agents local pour l'√©criture, relecture et correction du GDD Alteir (RPG narratif).
- Stack: LangGraph + MCP Notion + OpenAI (ou autres providers)
- Mod√®le principal: GPT-5-nano (rapide, √©conomique, reasoning int√©gr√©)
- 4 agents g√©n√©riques configur√©s par domaine (Writer, Reviewer, Corrector, Validator)
- Architecture hybride: R√¥le + DomainConfig pour extensibilit√©

## ü§ñ Mod√®les LLM

### OpenAI (Production)
```python
from langchain_openai import ChatOpenAI

# GPT-5 (Reasoning models)
llm = ChatOpenAI(
    model="gpt-5-nano",  # ou gpt-5, gpt-5-mini
    use_responses_api=True,
    reasoning={
        "effort": "minimal"  # minimal, low, medium, high
    },
    max_tokens=1000,
    # ‚ö†Ô∏è NE PAS utiliser temperature avec GPT-5 (non support√©)
)

# GPT-4 (Chat models classiques)
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=1.0,
    max_tokens=1000,
)
```

**IMPORTANT:** 
- **GPT-5** : Utilise `reasoning` au lieu de `temperature`
- **GPT-4** : Utilise `temperature` classique
- LangChain g√®re automatiquement la distinction via `use_responses_api`

### Multi-Provider Support
- **Toujours utiliser `LLMAdapter`** pour abstraction fournisseur
- Supporte: OpenAI, Anthropic, Mistral, Ollama (local)
- Structured Outputs quand disponible, sinon fallback JSON parsing

```python
from agents.base.llm_utils import LLMAdapter

adapter = LLMAdapter(llm)  # N'importe quel LLM
result = adapter.get_structured_output(prompt, schema=MySchema)
```

## üèóÔ∏è Architecture des Agents

### BaseAgent Pattern
```python
from agents.base.base_agent import BaseAgent, AgentResult
from agents.base.domain_config import DomainConfig

class MyAgent(BaseAgent):
    def __init__(self, domain_config: DomainConfig, llm=None):
        super().__init__(domain_config, llm)
    
    def process(self, input_data, context=None) -> AgentResult:
        # Utiliser self.domain_config pour sp√©cificit√©s
        # Utiliser self.llm pour appels LLM
        pass
```

### DomainConfig
- **1 config par domaine** (personnages, lieux, communaut√©s, etc.)
- D√©finit: template Notion, r√®gles validation, prompts par r√¥le
- Localisation: `config/domain_configs/`

### Agents G√©n√©riques
1. **WriterAgent**: G√©n√©ration contenu original
2. **ReviewerAgent**: Analyse coh√©rence narrative
3. **CorrectorAgent**: Correction linguistique
4. **ValidatorAgent**: Validation finale

## üìä Structured Outputs (IMPORTANT)

### Toujours Pr√©f√©rer Structured Outputs
```python
from pydantic import BaseModel, Field
from typing import List

class MyResult(BaseModel):
    field1: str = Field(description="...")
    field2: List[str]

# Utiliser LLMAdapter (multi-provider)
adapter = LLMAdapter(llm)
result = adapter.get_structured_output(
    prompt="...",
    schema=MyResult
)
# result est typ√©, pas de parsing manuel !
```

### NE PAS faire de parsing manuel fragile
‚ùå √âviter:
```python
if '[CORRECTION:' in line:  # Fragile, d√©pend du format texte
    parts = line.split(']', 1)
```

‚úÖ Utiliser:
```python
result = adapter.get_structured_output(prompt, schema=CorrectionResult)
for corr in result.corrections:  # Typ√©, fiable
    print(corr.type, corr.original)
```

## üîÑ Workflows LangGraph

### Pattern Standard
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class MyState(TypedDict):
    content: str
    metadata: dict

def node_function(state: MyState) -> dict:
    return {"content": "..."}

graph = StateGraph(MyState)
graph.add_node("node1", node_function)
graph.add_edge("node1", END)
app = graph.compile()
```

### Sauvegarde des R√©sultats
- **JSON** (`outputs/*.json`): √âtat complet, m√©tadonn√©es
- **Markdown** (`outputs/*.md`): Contenu format√©, lisible

## üîó Int√©gration Notion

### üö® R√àGLE CRITIQUE : Bac √† Sable UNIQUEMENT
**TOUTE CR√âATION doit se faire dans le bac √† sable jusqu'√† validation du projet.**
Voir `.cursor/rules/export-notion.mdc` pour la documentation compl√®te.

#### Bases de Bac √† Sable (√âCRITURE AUTORIS√âE) ‚úÖ
- **Personnages (1)** : `2806e4d21b458012a744d8d6723c8be1` 
- **Lieux (1)** : `2806e4d21b4580969f1cd7463a4c889c`

#### Bases Principales (LECTURE SEULE ‚ö†Ô∏è NE PAS √âCRIRE)
- **Personnages** : `1886e4d21b4581a29340f77f5f2e5885`
- **Lieux** : `1886e4d21b4581eda022ea4e0f1aba5f`
- **Communaut√©s** : `1886e4d21b4581dea4f4d01beb5e1be2`
- **Esp√®ces** : `1886e4d21b4581e9a768df06185c1aea`
- **Objets** : `1886e4d21b4581098024c61acd801f52`

### API Version
```python
# config/notion_config.py
API_VERSION = "2025-09-03"  # Support multi-source databases
```

### Outils MCP Disponibles
- `mcp_notionMCP_notion-search`: Recherche s√©mantique
- `mcp_notionMCP_notion-fetch`: R√©cup√©rer page/database
- `mcp_notionMCP_notion-create-pages`: Cr√©er pages
- `mcp_notionMCP_notion-update-page`: Modifier pages

### Pattern MCP
```python
# 1. Fetch database pour sch√©ma
database = mcp_notionMCP_notion-fetch(id=database_id)

# 2. Utiliser data_source_url pour recherche
results = mcp_notionMCP_notion-search(
    query="...",
    data_source_url=data_source_url
)

# 3. Cr√©er avec structure valid√©e
mcp_notionMCP_notion-create-pages(
    parent={"data_source_id": "..."},
    pages=[{"properties": {...}, "content": "..."}]
)
```

## üìù Conventions Code

### Nommage
- **Classes**: PascalCase (WriterAgent, DomainConfig)
- **Fonctions/Variables**: snake_case (process_content, domain_config)
- **Constantes**: UPPER_SNAKE_CASE (PERSONNAGES_CONFIG)

### Type Hints (OBLIGATOIRE)
```python
def process(self, content: str, context: Dict[str, Any] = None) -> AgentResult:
    pass
```

### Docstrings (Format Google)
```python
def my_function(param1: str) -> bool:
    """
    Description courte.
    
    Args:
        param1: Description du param√®tre
        
    Returns:
        Description du retour
    """
    pass
```

### Structure Fichiers
```
agents/
  base/
    base_agent.py          # Classe abstraite
    domain_config.py       # Syst√®me config
    llm_utils.py          # Adapter multi-provider
  writer_agent.py
  reviewer_agent.py
  ...

config/
  domain_configs/
    personnages_config.py  # Config compl√®te domaine
    lieux_config.py
    ...
  notion_config.py         # Config Notion/MCP

workflows/
  content_workflow.py      # Workflow LangGraph complet

outputs/                   # R√©sultats g√©n√©r√©s
  *.json
  *.md
```

## üé® Principes Narratifs (Domaine Personnages)

### R√®gles Cr√©atives
1. **Orthogonalit√© r√¥le ‚Üî profondeur**: Profondeur ‚â† r√¥le visible
2. **Structure Surface/Profondeur/Monde**: Gestes/Indices/Contraintes
3. **Temporalit√© IS/WAS/COULD-HAVE-BEEN**: Pr√©sent/Pass√©/Voie non prise
4. **Show > Tell**: Objets, rituels, traces > exposition
5. **Blancs actifs**: Zones d'ombre = actions possibles
6. **Relations concr√®tes**: Prix, dette, d√©lai, tabou

### Style
- Fran√ßais cru mais non esth√©tisant
- N√©ologismes avec glose br√®ve (5-8 mots)
- √âviter anglicismes non n√©cessaires
- Prose continue (pas tableaux comparatifs)

## ‚öôÔ∏è Configuration Environnement

### Variables .env
```bash
# LLM Provider
LLM_PROVIDER=openai  # ou anthropic, mistral, ollama
OPENAI_API_KEY=sk-...

# Notion
NOTION_TOKEN=secret_...
```

### Tests
```bash
# Test workflow complet
python workflows/content_workflow.py

# Test agent individuel
python agents/writer_agent.py

# Test avec provider sp√©cifique
LLM_PROVIDER=ollama python examples/corrector_structured_example.py
```

## üö® Erreurs Courantes √† √âviter

‚ùå Parsing manuel de texte LLM
‚ùå Hardcoder le provider (toujours via LLMAdapter)
‚ùå Oublier les type hints
‚ùå Ne pas valider avec le DomainConfig
‚ùå Ignorer les structured outputs quand disponibles
‚ùå Cr√©er des agents sp√©cialis√©s au lieu de configs
‚ùå Utiliser des mod√®les inexistants (v√©rifier docs OpenAI)

## ‚úÖ Bonnes Pratiques

‚úì Utiliser LLMAdapter pour abstraction provider
‚úì Structured Outputs avec Pydantic pour typage
‚úì DomainConfig pour sp√©cialisation (pas nouveaux agents)
‚úì Sauvegarder r√©sultats en JSON + Markdown
‚úì Tester avec plusieurs providers
‚úì Valider r√©f√©rences crois√©es Notion
‚úì Garder workflows LangGraph simples
‚úì Documenter avec type hints + docstrings

## üîß Debug & Monitoring

### Outputs
- Console: Progression temps r√©el
- `outputs/*.json`: √âtat complet workflow
- `outputs/*.md`: Contenu format√© + m√©triques

### LangGraph Studio
```bash
pip install langgraph-cli
langgraph dev
# Ouvrir http://localhost:8000
```

### Logs
- `[WRITER]`, `[REVIEWER]`, etc.: √âtapes workflow
- Scores: Coh√©rence, Compl√©tude, Qualit√© (0.0-1.0)
- Validation: Erreurs critiques vs warnings

## üìö R√©f√©rences Rapides

- **GPT-5-nano**: Mod√®le rapide OpenAI (ao√ªt 2025), `use_responses_api=True`
- **LLMAdapter**: `agents/base/llm_utils.py`
- **BaseAgent**: `agents/base/base_agent.py`
- **DomainConfig**: `agents/base/domain_config.py`
- **Notion API**: Version `2025-09-03` (multi-source)
- **Workflow**: `workflows/content_workflow.py`

