# Tests End-to-End (E2E) - SystÃ¨me Multi-Agents

Documentation complÃ¨te des tests E2E pour le systÃ¨me multi-agents GDD Alteir.

---

## ğŸ“‹ Vue d'Ensemble

Les tests E2E valident le **workflow complet** :  
`Brief â†’ Writer â†’ Reviewer â†’ Corrector â†’ Validator â†’ Export Notion`

### Structure des Tests

```
tests/
â”œâ”€â”€ conftest.py                         # Fixtures partagÃ©es
â”œâ”€â”€ run_e2e_tests.py                    # Script runner pratique
â”‚
â”œâ”€â”€ test_e2e_workflow_personnage.py     # E2E personnages (basique + profils)
â”œâ”€â”€ test_e2e_workflow_with_context.py   # E2E avec contexte Notion
â”œâ”€â”€ test_e2e_error_handling.py          # Gestion d'erreurs
â”‚
â”œâ”€â”€ test_writer_agent.py                # Tests WriterAgent (unit + integration)
â”œâ”€â”€ test_structured_outputs_agents.py   # Tests structured outputs
â”‚
â”œâ”€â”€ test_notion_api.py                  # Tests API Notion consolidÃ©s
â”œâ”€â”€ test_export_integration.py          # Tests export (existants)
â””â”€â”€ README_E2E_TESTS.md                 # Cette documentation
```

---

## ğŸš€ ExÃ©cution Rapide

### Tests Rapides (RecommandÃ© pour Dev)
```bash
# Unitaires uniquement (< 2 secondes)
python tests/run_e2e_tests.py quick
```

### Tests E2E Basiques
```bash
# E2E simples (~ 1 minute)
python tests/run_e2e_tests.py e2e-basic
```

### Tests E2E Complets
```bash
# Tous les E2E (~ 2-3 minutes)
python tests/run_e2e_tests.py e2e-only
```

### Suite ComplÃ¨te
```bash
# Tous les tests (~ 3-5 minutes)
python tests/run_e2e_tests.py full
```

---

## ğŸ“Š Types de Tests E2E

### 1. **test_e2e_workflow_personnage.py** âš¡ E2E Core

**Objectif** : Tester le workflow complet pour personnages

#### Tests Inclus

##### `TestE2EWorkflowPersonnageBasic`
- `test_e2e_personnage_minimal` : Workflow basique sans export
- `test_e2e_personnage_with_notion_export` : Workflow + export Notion sandbox

##### `TestE2EWorkflowLieu`
- `test_e2e_lieu_minimal` : Workflow complet pour un lieu

##### `TestE2EWriterProfiles`
- `test_e2e_orthogonal_depth` : Profil orthogonal_depth + major
- `test_e2e_vocation_pure` : Profil vocation_pure + supporting
- `test_e2e_mystere_non_resolu` : Profil mystere_non_resolu + minor

**Assertions** :
- âœ… Chaque agent retourne `success=True`
- âœ… Scores > seuils (coherence, completeness, quality)
- âœ… Page Notion crÃ©Ã©e avec propriÃ©tÃ©s correctes
- âœ… Outputs JSON + MD sauvegardÃ©s

**Temps** : ~30-60 secondes par test  
**CoÃ»t** : ~$0.005-0.01 par test (GPT-4o-mini)

**ExÃ©cution** :
```bash
# Tous les tests personnage
pytest tests/test_e2e_workflow_personnage.py -v -s

# Un test spÃ©cifique
pytest tests/test_e2e_workflow_personnage.py::TestE2EWorkflowPersonnageBasic::test_e2e_personnage_minimal -v -s
```

---

### 2. **test_e2e_workflow_with_context.py** ğŸ”— E2E Contexte

**Objectif** : Tester workflow avec rÃ©cupÃ©ration de contexte Notion

#### Tests Inclus

##### `TestE2EWorkflowWithContext`
- `test_e2e_with_communaute_context` : RÃ©fÃ©rence "Les Murmurateurs"
- `test_e2e_with_lieu_context` : RÃ©fÃ©rence "La Vieille Ville"
- `test_e2e_with_espece_context` : RÃ©fÃ©rence "Humain modifiÃ©"
- `test_e2e_with_multi_context` : RÃ©fÃ©rences multiples (communautÃ© + lieu + espÃ¨ce)

##### `TestE2EContextCache`
- `test_context_cache_performance` : VÃ©rifier accÃ©lÃ©ration cache (2x minimum)

**Assertions** :
- âœ… Contexte rÃ©cupÃ©rÃ© depuis Notion
- âœ… RÃ©fÃ©rences prÃ©sentes dans le contenu gÃ©nÃ©rÃ©
- âœ… Relations Notion correctement dÃ©finies
- âœ… Cache amÃ©liore performances (speedup > 2x)

**Temps** : ~60-90 secondes par test  
**CoÃ»t** : ~$0.01-0.02 par test

**ExÃ©cution** :
```bash
# Tous les tests contexte
pytest tests/test_e2e_workflow_with_context.py -v -s

# Test cache uniquement
pytest tests/test_e2e_workflow_with_context.py::TestE2EContextCache -v -s
```

---

### 3. **test_e2e_error_handling.py** âš ï¸ Gestion d'Erreurs

**Objectif** : Tester rÃ©silience et gestion d'erreurs

#### Tests Inclus

##### `TestE2EErrorHandling`
- `test_e2e_brief_vide` : Brief vide â†’ erreur claire
- `test_e2e_brief_trop_court` : Brief vague â†’ score complÃ©tude bas
- `test_e2e_validation_failed_no_export` : Validation Ã©chouÃ©e â†’ pas d'export
- `test_e2e_notion_api_error_simulation` : Erreur API Notion â†’ message clair

##### `TestE2EResilience`
- `test_e2e_contenu_incomplet_detection` : DÃ©tection champs manquants
- `test_e2e_workflow_state_consistency` : Ã‰tat workflow cohÃ©rent

**Assertions** :
- âœ… Erreurs dÃ©tectÃ©es proprement (pas de crash)
- âœ… Messages d'erreur clairs
- âœ… Ã‰tat workflow reste cohÃ©rent
- âœ… Validation bloque export si invalide

**Temps** : ~10-30 secondes par test (certains rapides)  
**CoÃ»t** : ~$0.005 par test

**ExÃ©cution** :
```bash
# Tous les tests erreurs
pytest tests/test_e2e_error_handling.py -v -s
```

---

### 4. **test_writer_agent.py** âœï¸ Tests WriterAgent

**Objectif** : Tester WriterAgent isolÃ©ment

#### Tests Inclus

##### `TestWriterAgentBasic`
- `test_writer_generate_personnage` : GÃ©nÃ©ration personnage basique
- `test_writer_generate_lieu` : GÃ©nÃ©ration lieu basique

##### `TestWriterAgentFormat`
- `test_writer_markdown_structure_personnage` : VÃ©rifier structure markdown
- `test_writer_markdown_structure_lieu` : VÃ©rifier sections lieu

##### `TestWriterAgentConfig`
- `test_writer_orthogonal_depth` : Config orthogonal_depth
- `test_writer_vocation_pure` : Config vocation_pure
- `test_writer_mystere_non_resolu` : Config mystere_non_resolu

##### `TestWriterAgentWithContext`
- `test_writer_with_notion_context` : GÃ©nÃ©ration avec contexte
- `test_writer_without_context` : GÃ©nÃ©ration sans contexte (baseline)

**Assertions** :
- âœ… Contenu gÃ©nÃ©rÃ© > 100 caractÃ¨res
- âœ… Structure markdown valide
- âœ… Champs essentiels prÃ©sents
- âœ… MÃ©tadonnÃ©es complÃ¨tes (intent, level, dialogue_mode)

**Temps** : ~15-30 secondes par test  
**CoÃ»t** : ~$0.003-0.005 par test

**ExÃ©cution** :
```bash
# Tous les tests WriterAgent
pytest tests/test_writer_agent.py -v -s

# Tests config uniquement
pytest tests/test_writer_agent.py::TestWriterAgentConfig -v -s
```

---

## âš™ï¸ Configuration

### PrÃ©requis

1. **Variables d'environnement** (fichier `.env`)
```bash
NOTION_TOKEN=secret_...
OPENAI_API_KEY=sk-...
```

2. **DÃ©pendances installÃ©es**
```bash
pip install -r requirements.txt
```

3. **AccÃ¨s bases Notion**
   - **Sandbox** (Ã©criture) : Personnages (1), Lieux (1)
   - **Principales** (lecture) : Personnages, Lieux, CommunautÃ©s, EspÃ¨ces

### Fixtures PartagÃ©es (`conftest.py`)

- `notion_token` : Token Notion (skip si absent)
- `notion_headers` : Headers pour API Notion
- `sandbox_databases` : IDs des bases sandbox
- `main_databases` : IDs des bases principales
- `test_llm` : LLM configurÃ© (GPT-4o-mini)
- `test_llm_fast` : LLM rapide (tokens rÃ©duits)
- `notion_page_tracker` : Cleanup automatique des pages crÃ©Ã©es
- `temp_output_dir` : RÃ©pertoire temporaire pour outputs
- `sample_brief_personnage` : Brief test personnage
- `sample_brief_lieu` : Brief test lieu

---

## ğŸ¯ StratÃ©gie de Test

### Pyramide de Tests

```
         ğŸ”º E2E (lents, coÃ»teux)
        /    \
       /      \  
      / IntÃ©g  \
     /   (API)  \
    /____________\
   Unit (rapides)
```

### Quand Lancer Quels Tests ?

#### DÃ©veloppement Actif
```bash
# Tests rapides Ã  chaque changement
python tests/run_e2e_tests.py quick
```

#### Avant Commit Local
```bash
# E2E basiques pour validation rapide
python tests/run_e2e_tests.py e2e-basic
```

#### Avant Push / PR
```bash
# Suite complÃ¨te
python tests/run_e2e_tests.py full
```

#### CI/CD
```bash
# StratÃ©gie deux Ã©tapes:
# 1. Fast check (unit)
pytest tests/ -m "unit" -v --tb=short

# 2. Full check si unit pass
pytest tests/ -v --tb=short
```

---

## ğŸ’° CoÃ»t LLM EstimÃ©

| Mode | Appels LLM | CoÃ»t (GPT-4o-mini) | Temps |
|------|------------|-------------------|-------|
| `quick` | 0 | $0 | < 2s |
| `e2e-basic` | 2-3 | ~$0.01 | ~1 min |
| `e2e-only` | 10-15 | ~$0.02-0.03 | ~2-3 min |
| `full` | 15-20 | ~$0.03-0.05 | ~3-5 min |

**Note** : CoÃ»ts basÃ©s sur GPT-4o-mini (~$0.15/1M input tokens, ~$0.60/1M output tokens)

---

## ğŸ” Marqueurs Pytest

Les tests utilisent des marqueurs pour filtrage :

```ini
markers =
    e2e          : Tests end-to-end complets
    slow         : Tests lents (> 10 secondes)
    llm_api      : Tests utilisant API LLM rÃ©elle
    notion_api   : Tests utilisant API Notion rÃ©elle
    unit         : Tests unitaires rapides
    integration  : Tests d'intÃ©gration
```

### Exemples de Filtrage

```bash
# Seulement tests rapides
pytest tests/ -m "unit" -v

# Tout sauf les lents
pytest tests/ -m "not slow" -v

# Seulement E2E
pytest tests/ -m "e2e" -v

# E2E sans API Notion
pytest tests/ -m "e2e and not notion_api" -v
```

---

## ğŸ› Debug

### Afficher les sorties print
```bash
pytest tests/test_e2e_workflow_personnage.py -v -s
```

### Afficher traceback complet
```bash
pytest tests/ -v --tb=long
```

### ArrÃªter au premier Ã©chec
```bash
pytest tests/ -v -x
```

### Lancer un test spÃ©cifique
```bash
pytest tests/test_e2e_workflow_personnage.py::TestE2EWorkflowPersonnageBasic::test_e2e_personnage_minimal -v -s
```

### Voir les tests disponibles
```bash
pytest tests/ --collect-only
```

---

## ğŸ§¹ Cleanup Automatique

Les tests utilisent la fixture `notion_page_tracker` pour cleanup automatique :

```python
def test_something(notion_page_tracker):
    # CrÃ©er page
    page_id = create_page(...)
    
    # Ajouter au tracker
    notion_page_tracker.append(page_id)
    
    # La page sera automatiquement archivÃ©e aprÃ¨s le test
```

**Cleanup manuel** (si test Ã©choue avant cleanup) :

1. Aller dans Notion â†’ Bac Ã  sable
2. Filtrer par nom commenÃ§ant par `TEST_`
3. Archiver manuellement

---

## âœ… Checklist Avant Commit

- [ ] `python tests/run_e2e_tests.py quick` âœ… (< 2s)
- [ ] `python tests/run_e2e_tests.py e2e-basic` âœ… (~1 min)
- [ ] Code review des changements
- [ ] Documentation Ã  jour si nÃ©cessaire

**Checklist complÃ¨te avant PR** :

- [ ] `python tests/run_e2e_tests.py full` âœ… (~3-5 min)
- [ ] Linter passes (`read_lints` si applicable)
- [ ] CHANGELOG.md mis Ã  jour
- [ ] Tests nouveaux/modifiÃ©s documentÃ©s

---

## ğŸ“ˆ MÃ©triques

### Temps d'ExÃ©cution (Estimations)

| Fichier Test | Tests | Temps Moyen |
|--------------|-------|-------------|
| `test_e2e_workflow_personnage.py` | 6 | ~3-4 min |
| `test_e2e_workflow_with_context.py` | 5 | ~3-5 min |
| `test_e2e_error_handling.py` | 6 | ~1-2 min |
| `test_writer_agent.py` | 10 | ~2-3 min |
| `test_notion_api.py` | 12 | ~30-60s |

**Total suite E2E complÃ¨te** : ~10-15 minutes

---

## ğŸ”§ Maintenance

### Ajouter un Nouveau Test E2E

1. **Choisir le fichier appropriÃ©** :
   - Workflow basique â†’ `test_e2e_workflow_personnage.py`
   - Avec contexte â†’ `test_e2e_workflow_with_context.py`
   - Gestion erreur â†’ `test_e2e_error_handling.py`

2. **CrÃ©er le test** :
```python
@pytest.mark.e2e
@pytest.mark.slow
@pytest.mark.llm_api
def test_mon_nouveau_cas(test_llm, temp_output_dir):
    """Description claire du test"""
    brief = "..."
    workflow = ContentWorkflow(PERSONNAGES_CONFIG, llm=test_llm)
    state = workflow.run(brief)
    
    assert state["validator_metadata"]["is_valid"]
    # ... autres assertions
```

3. **Tester** :
```bash
pytest tests/test_e2e_workflow_personnage.py::test_mon_nouveau_cas -v -s
```

4. **Documenter** : Ajouter dans cette doc si nÃ©cessaire

---

## ğŸ“ Bonnes Pratiques

### âœ… DO

- Utiliser `test_llm` fixture pour LLM rÃ©el
- Utiliser `notion_page_tracker` pour cleanup automatique
- Marquer tests avec `@pytest.mark.e2e`, `@pytest.mark.slow`, etc.
- Afficher logs utiles avec `print()` (visible avec `-s`)
- Assertions claires avec messages d'erreur explicites
- Documenter le but du test dans le docstring

### âŒ DON'T

- Ne PAS crÃ©er pages Notion sans cleanup
- Ne PAS oublier les marqueurs pytest
- Ne PAS faire de tests trop longs (> 2 min)
- Ne PAS Ã©crire dans bases principales (lecture seule)
- Ne PAS hardcoder les IDs de bases (utiliser fixtures)

---

## ğŸ”— RÃ©fÃ©rences

- **Tests Export** : `README_EXPORT_TESTS.md`
- **Tests Notion** : `README_NOTION_TESTS.md`
- **Config Pytest** : `pytest.ini`
- **Fixtures** : `conftest.py`
- **StratÃ©gie Testing** : `.cursor/rules/testing-strategy-v1.mdc`

